{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e626f0",
   "metadata": {},
   "source": [
    "# ROI Pooling Layer\n",
    "\n",
    "![](https://deepsense.ai/wp-content/uploads/2017/02/roi_pooling-1.gif.pagespeed.ce.5V5mycIRNu.gif)\n",
    "<center>Image taken from <a href=\"https://deepsense.ai/region-of-interest-pooling-explained/\">here</a></center>\n",
    "<br><br>\n",
    "\n",
    "The last part that goes into making Faster R-CNN possible is the ROI Pooling layer! \n",
    "\n",
    "It might sound complex, but this concept is straightforward! First, we pre-defined some output sizes (e.g., 2x2, 5x5, 7x7). After a CNN part of the network produces features and RPN produces ROI proposals, ROI pooling takes each ROI as an input and applies its position and size on the feature maps generated by a CNN network. Each of these regions is split into several pieces to get the predefined size (e.g., 2x2). We take each sub-section and apply the MaxPooling on top of it (select the most significant number).\n",
    "\n",
    "**Learn more about ROI Pooling:**\n",
    "- https://towardsdatascience.com/understanding-region-of-interest-part-1-roi-pooling-e4f5dd65bb44\n",
    "- https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af\n",
    "- https://deepsense.ai/region-of-interest-pooling-explained/\n",
    "- (Optional) https://kaushikpatnaik.github.io/annotated/papers/2020/07/04/ROI-Pool-and-Align-Pytorch-Implementation.html\n",
    "\n",
    "### Steps:\n",
    "1. Import dependencies\n",
    "2. Define the RoIPooling layer\n",
    "\n",
    "### Topics covered and learning objectives\n",
    "- RoI Pooling layer\n",
    "\n",
    "### Time estimates:\n",
    "- Reading/Watching materials: 15min\n",
    "- Exercises: 3-5min\n",
    "<br><br>\n",
    "- **Total**: ~20min\n",
    "\n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d40ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D\n",
    "\n",
    "from tests import test_ROI_Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ff549",
   "metadata": {},
   "source": [
    "### Exercise 1 Complete the call function in the **RoIPooling** layer\n",
    "\n",
    "**Tutorial: How to create a custom Keras layer**: \n",
    "- https://sparrow.dev/keras-custom-layer/\n",
    "- https://faroit.com/keras-docs/2.0.1/layers/writing-your-own-keras-layers/\n",
    "\n",
    "The call method accepts three (3) inputs â†’ feature maps from the previous layer, ROIs from RPN, and box_indexes (IDs of images that correspond to each ROI).\n",
    "\n",
    "Your task will be to perform RoIPooling by using the crop_and_resize function from TensorFlow. The complete documentation can be found [here](https://www.tensorflow.org/api_docs/python/tf/image/crop_and_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoIPooling(Layer):\n",
    "    \n",
    "    def __init__(self, size=(7, 7)):\n",
    "        \"\"\"\n",
    "        RoI Pooling layer\n",
    "        \n",
    "        Args:\n",
    "            :param size (tuple): size of the pooling output \n",
    "        \"\"\"\n",
    "        \n",
    "        self.size = size\n",
    "        super(RoIPooling, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Build method is used to define weights for the custom Keras method\n",
    "        \n",
    "        Args:\n",
    "            :param input_shape (list): Shape of the input of the previous layer in a network\n",
    "        \"\"\"\n",
    "        \n",
    "        self.shape = input_shape\n",
    "        super(RoIPooling, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "        In case your layer modifies the shape of its input, \n",
    "        you should specify here the shape transformation logic. \n",
    "        This allows Keras to do automatic shape inference.\n",
    "        \n",
    "        Args:\n",
    "            :param input_shape (list): Shape of the input of the previous layer in a network\n",
    "            \n",
    "        Source: Taken from article: https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html\n",
    "        \"\"\"\n",
    "        a=input_shape[1][0]\n",
    "        b=self.size[0]\n",
    "        c=self.size[1]\n",
    "        d=input_shape[0][3]\n",
    "        return (a,b,c,d)\n",
    "        \n",
    "    def call(self, feature_maps, rois, box_indexes, **kwargs):\n",
    "        \"\"\"\n",
    "        Main Layer's logic.\n",
    "        \n",
    "        Args:\n",
    "            :param feature_maps: Feature maps generated by RPN. Dimensions 4D, example: [None, None, None, 512]\n",
    "            :param rois: List of rois with 4 coordinates each. Example: [None, 4]\n",
    "            :param box_indexes:  A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`. \n",
    "                                The value of `box_ind[i]` specifies the image that the `i`-th box refers to.\n",
    "                                \n",
    "        Returns:\n",
    "            x - pooled inputs with size: [None, self.size[0], self.size[1], feature_maps[-1]] -> Example: [None, 7, 7, 512]\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = None\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE\n",
    "test_ROI_Pooling(RoIPooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d9bd8",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "\n",
    "Since we haven't implemented the whole Faster R-CNN, but its most essential parts, we suggest that you go through some blogs and implementations covering them in much more depth. But taking the length and training time into account, that might take several days to a week! \n",
    "\n",
    "\n",
    "Links to follow:\n",
    "- Implementation PT1: https://dongjk.github.io/code/object+detection/keras/2018/05/21/Faster_R-CNN_step_by_step,_Part_I.html\n",
    "- Implementation PT2: https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html\n",
    "- PyTorch: https://github.com/clemkoa/faster-rcnn\n",
    "- Keras: https://github.com/you359/Keras-FasterRCNN\n",
    "\n",
    "\n",
    "For now, you have covered the main parts of the two-staged object detection algorithms, and it's time to switch a line and tackle some bleeding-edge object detection networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf34459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

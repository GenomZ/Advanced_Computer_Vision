{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e626f0",
   "metadata": {},
   "source": [
    "# Region Proposal Network (RPN)\n",
    "\n",
    "\n",
    "![RPN](https://www.researchgate.net/publication/329263432/figure/fig3/AS:698144681623558@1543462071466/Region-Proposal-Network-RPN.png)\n",
    "<center>Image taken from <a href=\"https://www.researchgate.net/figure/Region-Proposal-Network-RPN_fig3_329263432\">here</a></center>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "In this notebook, you'll write the second building block of Faster R-CNN, the **Region Proposal Network** RPN, from scratch using the Keras library.\n",
    "\n",
    "In the first version of the R-CNN, we used the Selective Search algorithm to generate ROIs, which showed promising results, but the whole prediction/training process was very slow! RPN allows us to generate ROIs on the fly by combining Anchor boxes and CNN architecture.\n",
    "\n",
    "### What's the architecture?\n",
    "\n",
    "Region Proposal Network has one standard CNN layer, which accepts outputs from a pre-trained base_network (e.g., VGG16) and has two output heads (layers) - classification, which checks if that part of an image contains an object or not), and regression head for bbox coordinates predictions.\n",
    "\n",
    "Having two outputs, RPN needs a two-part loss function! For the classification part, we use binary_crossentropy, and for the regression, MSE (Mean Squared Error).\n",
    "\n",
    "\n",
    "### RPN Details:\n",
    "- https://medium.com/egen/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9\n",
    "- https://towardsdatascience.com/region-proposal-network-a-detailed-view-1305c7875853\n",
    "- https://www.coursera.org/lecture/convolutional-neural-networks/region-proposals-optional-aCYZv\n",
    "\n",
    "\n",
    "### Steps:\n",
    "1. Import dependencies\n",
    "2. Write the RPN model\n",
    "3. Define the model\n",
    "4. Compile the RPN model\n",
    "\n",
    "### Topics covered and learning objectives\n",
    "- Region Proposal Network (RPN)\n",
    "\n",
    "### Time estimates:\n",
    "- Reading/Watching materials: 20min\n",
    "- Exercises: 15min\n",
    "<br><br>\n",
    "- **Total**: ~35h\n",
    "\n",
    "\n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d40ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Input, Dense\n",
    "from tests import TEST_RPN_MODEL_LOSS, TEST_RPN_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b5237",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Exercise 1: Write the RPN network\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*hdny9cskat-RjUPuq5ze4A.jpeg)\n",
    "<center>Image taken from <a href=\"https://towardsdatascience.com/region-proposal-network-a-detailed-view-1305c7875853\">here</a></center>\n",
    "<br><br>\n",
    "\n",
    "The image above shows the resulting architecture of this exercise.\n",
    "\n",
    "**Steps:**\n",
    "- Define the Input layer that accepts shape (None, None, 512)\n",
    "- Define Conv2D that has kernel size of 3x3 and 512 filters, padding is same here, activation ReLu\n",
    "- Define the first output layer for the regression part\n",
    "    - This layer should have 4 * **k** filters, kernel size is 1x1, no activation function, and **name** should be \"location\"\n",
    "    - Inputs to this layer is the first Conv2D layer that you defined\n",
    "- Define the second output layer for the classification part\n",
    "    - This layer should have 1 * **k** filters, kernel size is 1x1, activation sigmoid, and **name** should be \"classification\"\n",
    "    - Inputs to this layer is the first Conv2D layer that you defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bfe2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of anchors\n",
    "k=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f1081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_tile = Input(shape=(None, None, 512))\n",
    "convolution_3x3 = Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    activation=\"relu\",\n",
    "    name=\"3x3\"\n",
    ")(feature_map_tile)\n",
    "\n",
    "output_deltas = Conv2D(\n",
    "    filters= 4 * k,\n",
    "    kernel_size=(1, 1),\n",
    "    name=\"location\"\n",
    ")(convolution_3x3)\n",
    "\n",
    "output_scores = Conv2D(\n",
    "    filters=1 * k,\n",
    "    kernel_size=(1, 1),\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"classification\"\n",
    ")(convolution_3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a50f9e",
   "metadata": {},
   "source": [
    "### Exercise 2: Define the model\n",
    "\n",
    "By using the *Model* keras object, define the RPN. \n",
    "\n",
    "For the **inputs** argument, set it to the Input layer you specified in the last exercise. And for the **outputs**, a list that contains two output layers you've defined (classification and location/regression layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37808030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[feature_map_tile], outputs=[output_scores, output_deltas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfe9f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:green>IMPLEMENTATION IS CORRECT! GOOD JOB!</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO TEST YOUR MODEL\n",
    "TEST_RPN_MODEL(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374156d",
   "metadata": {},
   "source": [
    "### Exercise 2: Compile the model\n",
    "\n",
    "Use an optimizer of your choice. And for the loss put this Python dict: \n",
    "\n",
    "**{'classification':\"binary_crossentropy\", 'location':\"mse\"}** \n",
    "\n",
    "NOTE: Keys are the NAMEs of layers you defined, and values are loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27662147",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'classification':\"binary_crossentropy\", 'location':\"mse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d565e887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:green>IMPLEMENTATION IS CORRECT! GOOD JOB!</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO TEST YOUR LOSS\n",
    "TEST_RPN_MODEL_LOSS(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67ddbb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "3x3 (Conv2D)                    (None, None, None, 5 2359808     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, None, None, 9 4617        3x3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "location (Conv2D)               (None, None, None, 3 18468       3x3[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 2,382,893\n",
      "Trainable params: 2,382,893\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50afc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
